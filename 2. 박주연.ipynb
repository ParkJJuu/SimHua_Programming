{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPwmmTGIBkJ8XyAKTss17MP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["수집한 이미지를 학습 데이터와 평가 데이터로 구분하는 함수"],"metadata":{"id":"aCg4oCFQ1NBg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRgEoNNRwt52"},"outputs":[],"source":["import os\n","import shutil\n","from bing_image_downloader.bing_image_downloader import downloader\n","'''\n","**********구글 이미지 다운로드*********\n","오류가 나서 주석으로만 넣어놓음. \n","from google_images_download import google_images_download\n","---------------------------------------------------------\n","'''\n","\n","directory_list = [\n","    './custom_dataset/train/',\n","    './custom_dataset/test/',\n","]\n","\n","# 초기 디렉토리 만들기\n","for directory in directory_list:\n","    if not os.path.isdir(directory):\n","        os.makedirs(directory)\n","\n","# 수집한 이미지를 학습 데이터와 평가 데이터로 구분하는 함수\n","def dataset_split(query, train_cnt):\n","    # 학습 및 평가 데이터셋 디렉토리 만들기\n","    for directory in directory_list:\n","        if not os.path.isdir(directory + '/' + query):\n","            os.makedirs(directory + '/' + query)\n","    # 학습 및 평가 데이터셋 준비하기\n","    cnt = 0\n","    for file_name in os.listdir(query):\n","        if cnt < train_cnt:\n","            print(f'[Train Dataset] {file_name}')\n","            shutil.move(query + '/' + file_name, './custom_dataset/train/' + query + '/' + file_name)\n","        else:\n","            print(f'[Test Dataset] {file_name}')\n","            shutil.move(query + '/' + file_name, './custom_dataset/test/' + query + '/' + file_name)\n","        cnt += 1\n","    shutil.rmtree(query)"]},{"cell_type":"markdown","source":["데이터셋 불러오기"],"metadata":{"id":"dr80P3zG1iMG"}},{"cell_type":"code","source":["# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n","transforms_train = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n","])\n","\n","transforms_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","data_dir = './custom_dataset'\n","train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n","test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'test'), transforms_test)\n","\n","train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=4)\n","test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=4, shuffle=True, num_workers=4)\n","\n","print('Train_Datasets_Size :', len(train_datasets))\n","print('Test_Datasets_Size :', len(test_datasets))\n","\n","class_names = train_datasets.classes\n","print('Class:', class_names)"],"metadata":{"id":"n-ngrxrpzaEO"},"execution_count":null,"outputs":[]}]}